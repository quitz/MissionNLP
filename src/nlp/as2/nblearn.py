# Learn a naive bayes classification from input dir
import sys
from dircache import listdir
import string
from math import log10
from collections import Counter

DEF_KEY = "__default__"
PRIOR_KEY = "__prior__"
TRUE_KEY = "true_review"
FALSE_KEY = "false_review"
POS_KEY = "pos_review"
NEG_KEY = "neg_review"

NEG = "negative_polarity"
POS = "positive_polarity"
FALSE = "/deceptive_from_MTurk"
TRUTH_NEG = "/truthful_from_Web"
TRUTH_POS = "/truthful_from_TripAdvisor"

#generated by getting top 50 occuring words  
# my_stop = set([ite for ite, it in true_review_token_ctr.most_common(50)]) 
# my_stop = my_stop.union(set([ite for ite, it in false_review_token_ctr.most_common(50)]))
    
my_stop = set(['all', 'one', 'rooms', 'staff', 'from', 'would', 'there', 'had', 'to', 'location', 'was', 'that', 'very', 'hotel', 'but', 'they', 'not', 'with', 'like', 'me', 'room', 'this', 'us', 'were', 'my', 'are', 'and', 'is', 'it', 'an', 'as', 'at', 'have', 'in', 'our', 'out', 'for', 'chicago', 'when', 'stayed', 'you', 'be', 'we', 'stay', 'a', 'on', 'great', 'service', 'i', 'of', 'no', 'so', 'the'])

# generated by getting words occuring wit similar frequency
# all_a = set([ite+str(it) for ite, it in true_review_token_ctr.most_common() ])
# all_b = set([ite+str(it) for ite, it in false_review_token_ctr.most_common() ])
# my_stop_2= [ite[:-1] for ite in all_a.intersection(all_b) ]
my_stop_2 = set(['daytime', 'screaming', 'disgusting', 'sparkling', 'benedict', 'tank', 'unlike', 'fireplace', 'explaining', 'fourstar', 'aka', 'oneway', 'basic', 'addressed', 'moist', 'losing', 'cockroach', 'eno', 'doing', 'abysmal', 'meant', 'haven', 'rethink', 'grace', 'inhouse', 'combine', 'regular', 'cheerfully', 'ratings', 'comes', 'result', 'alternative', 'responsibility', 'martini', 'impolite', 'counted', 'honoring', 'crt', 'cane', 'aspires', 'believed', 'supplies', 'repulsive', 'suit', 't', 'au', 'torn', 'retrieved', 'notably', 'posting', 'foreign', 'attitude', 'indifferent', 'everyones', 'perks', 'coolest', 'spas', 'whirlpool', 'frustratingly', 'shoulders', 'stare', 'appetizers', 'appear', 'inexpensive', 'marginally', 'heartily', 'partake', 'cloud', 'adjoining', 'drawer', 'twonight', 'product', 'extrodinary', 'plugged', 'warn', 'bench', 'amateur', 'handed', 'bumping', 'combined', 'layout', 'flavorless', 'break', 'opportunity', 'trains', 'consumer', 'unbelieveable', 'wrinkled', 'roach', 'yourself', 'finger', 'pieces', 'sooner', 'add', 'swissotels', 'greet', 'icing', 'seek', 'bunch', 'lcd', 'strip', 'sooo', 'parties', 'complimentary', 'enthusiastic', 'equipment', 'actual', 'crowds', 'locating', 'marks', 'fuzzy', 'fifth', 'thirdly', 'sunny', 'ways', 'canceled', 'leading', 'pregnant', 'drag', 'true', 'scenic', 'bite', 'platinum', 'wonderfully', 'permitted', 'drinking', 'historical', 'specific', 'checks', 'ordering', 'privacy', 'apartments', 'speedy', 'friendliest', 'excursion', 'massive', 'charlie', 'among', 'handle', 'film', 'select', 'lucky', 'mental', 'refreshed', 'eight', 'explore', 'evidently', 'yogurt', 'custom', 'unaware', 'inform', 'messages', 'attacked', 'chaos', 'constant', 'gas', 'largely', 'attendant', 'personality', 'groceries', 'nonallergenic', 'until', 'witnessed', 'andor', 'acknowledge', 'scent', 'moving', 'impact', 'bugs', 'cigar', 'inquire', 'piece', 'purpose', 'rumpled', 'hide', 'echo', 'reaked', 'rockers', 'marios', 'fine', 'inand', 'unwilling', 'tattered', 'complete', 'cases', 'summer', 'til', 'crummy', 'gourmet', 'reluctant', 'handsome', 'technically', 'differently', 'mom', 'surround', 'rundown', 'drab', 'gray', 'record', 'prolonged', 'reclean', 'extended', 'tubs', 'wind', 'latest', 'routine', 'curtain', 'dead', 'quoted', 'reflected', 'ding', 'spilled', 'efficiently', 'yup', 'shoe', 'fortunate', 'fries', 'availability', 'fabulously', 'prearrival', 'treats', 'highlight', 'appetizer', 'person', 'applies', 'surcharge', 'decade', 'downgraded', 'electrical', 'tacky', 'doll', 'superior', 'bump', 'dreary', 'grandeur', 'bring', 'limp', 'stuck', 'suv', 'benefit', 'toe', 'woefully', 'america', 'depending', 'create', 'pinch', 'remarkable', 'palace', 'bass', 'repeat', 'banging', 'studio', 'overcharged', 'log', 'built', 'headphones', 'fascinating', 'aid', 'switch', 'understaffed', 'factor', 'inexplicably', 'camera', 'sparkled', 'video', 'fellow', 'trust', 'mildew', 'sweets', 'inviting', 'immediately', 'disagreement', 'suffice', 'unload', 'dna', 'virtual', 'tomato', 'owned', 'activity', 'jacuzzi', 'convince', 'sore', 'onebedroom', 'interrupted', 'par', 'foam', 'stair', 'reverse', 'hearing', 'typically', 'primarily', 'approach', 'drunks', 'displays', 'aforementioned', 'style', 'sill', 'settings', 'necessarily', 'utilize', 'spaces', 'learned', 'runny', 'occupants', 'attendees', 'accidentally', 'wed', 'utter', 'absence', 'lap', 'wants', 'cheaply', 'tops', 'privilege', 'unprofessional', 'sat', 'greater', 'asthmatic', 'flushing', 'cards', 'hire', 'minded', 'heads', 'adjust', 'dancing', 'unless', 'lame', 'pleasurable', 'sometime', 'discomfort', 'fashion', 'tools', 'resembled', 'promising', 'seedy', 'permeated', 'fight', 'age', 'refrigerator', 'basis', 'horror', 'heading', 'typical', 'moments', 'content', 'rug', 'path', 'repeatedly', 'silver', 'latte', 'reviewing', 'visitors', 'yuck', 'featured', 'utilized', 'aroma', 'acceptable', 'recovering', 'inquired', 'suitcase', 'awake', 'bathrobes', 'resulting', 'rep', 'pricing', 'rates', 'clients', 'wouldve', 'lured', 'procedure', 'gel', 'california', 'manhattan', 'green', 'ideas', 'crappy', 'securing', 'ranges', 'million', 'flatscreen', 'snobbery', 'whistled', 'inappropriate', 'stone', 'grapes', 'restraunt', 'dropping', 'imagine', 'sunglasses', 'disturb', 'efforts', 'frankly', 'exceed', 'laundered', 'lesson', 'partner', 'control', 'hop', 'listed', 'bumps', 'nickel', 'base', 'unusable', 'marketing', 'cherry', 'sympathetic', 'poisoning', 'exceeds', 'rehearsal', 'invisible', 'proper', 'unimpressed', 'highspeed', 'recession', 'hook', 'chilly', 'hurt', 'ultramodern', 'pricy', 'specially', 'rarely', 'yearly', 'mission', 'fivestar', 'somebody', 'wearing', 'adventure', 'uptodate', 'staring', 'costing', 'receive', 'patron', 'assisting', 'mccormick', 'chichi', 'woudl', 'injury', 'steakhouse', 'during', 'carpeting', 'honestly', 'advised', 'artwork', 'respite', 'sensitive', 'explicitly', 'unbelievable', 'involved', 'solely', 'patches', 'learn', 'starting', 'heartbeat', 'ditch', 'encounter', 'described', 'definitly', 'shortage', 'afterwards', 'scheduling', 'mechanical', 'dresser', 'grill', 'errors', 'becoming', 'unwelcoming', 'sticking', 'towners', 'hd', 'budge', 'peoples', 'acting', 'ikea', 'loves', 'delighted', 'glossy', 'assumed', 'matched', 'overlooking', 'cooking', 'sounding', 'fewer', 'arose', 'positives', 'audio', 'keycard', 'skip', 'smoothly', 'c', 'tray', 'luster', 'class', 'greets', 'further', 'papers', 'flew', 'remodel', 'inspiring', 'wire', 'hidden', 'cellphone', 'vacations', 'priviledges', 'flushed', 'investigate', 'chocolates', 'brings', 'photographs', 'safely', 'tempted', 'rusty', 'thankful', 'overlooks', 'cultural', 'surpassed', 'theatre', 'def', 'seeming', 'lodge', 'aesthetic', 'forgot', 'twist', 'unbelievably', 'feels', 'toys', 'insects', 'interact', 'pasta', 'bag', 'forms', 'wooden', 'flexible', 'hospitable', 'aerobic', 'melted', 'womens', 'rule', 'forcing', 'sum', 'anyways', 'toothpaste', 'overlook', 'upgrading', 'reaching', 'ands', 'matter', 'served', 'pie', 'showering', 'pristine', 'conduct', 'peeve', 'individual', 'waiter', 'courtesy', 'detract', 'office', 'wonder', 'plague', 'advertise', 'advertising', 'skipping', 'dissipated', 'positive', 'dragged', 'unloading', 'stately', 'complicated', 'refill', 'blamed', 'conclusion', 'commented', 'worker', 'iphone', 'thoughtful', 'unfinished', 'posted', 'stunned', 'premises', 'cafes', 'message', 'housekeepers', 'intend', 'timely', 'likely', 'slowed', 'seasoned', 'disdain', 'chains', 'partying', 'cozy', 'rang', 'gentle', 'afternoon', 'assisted', 'worlds', 'regards', 'rated', 'awoke', 'attic', 'example', 'promises', 'ahead', 'sipping', 'severe', 'affect', 'atrium', 'dramatically', 'corners', 'everytime', 'competition', 'attempts', 'bothered', 'disinterested', 'nobody', 'tall', 'worried', 'victorian', 'freshener', 'gripe', 'overcooked', 'students', 'concerned', 'noises', 'info', 'awkward', 'uninterested', 'bunny', 'metropolitan', 'international', 'busy', 'pretended', 'systems', 'glitch', 'leather', 'plane', 'mailed', 'infant', 'familiar', 'damp', 'celebration', 'annoyance', 'touristy', 'disgusted', 'accepting', 'downright', 'bathtub', 'troubles', 'dents', 'frequented', 'fifteen', 'deadline', 'vendor', 'desks', 'miss', 'assume', 'declined', 'changing', 'glass', 'realizing', 'rushed', 'overhyped', 'funeral', 'scratches', 'orders', 'eager', 'extraordinary', 'wet', 'bedrooms', 'slumber', 'gotta', 'knowledge', 'terry', 'fulfill', 'promise', 'stick', 'basket', 'undergo', 'omelettes', 'neck', 'shine', 'recieved', 'fooled', 'alert', 'stuffed', 'fear', 'showertub', 'detail', 'neglected', 'arrogant', 'shaped'])

stop_words1 = set(["a", "about", "above", "after", "again", "against", "all", "am", "an", "and", "any", "are", "arent", "as", "at", "be", "because", "been", "before", "being", "below", "between", "both", "but", "by", "cant", "cannot", "could", "couldnt", "did", "didnt", "do", "does", "doesnt", "doing", "dont", "down", "during", "each", "few", "for", "from", "further", "had", "hadnt", "has", "hasnt", "have", "havent", "having", "he", "hed", "hell", "hes", "her", "here", "heres", "hers", "herself", "him", "himself", "his", "how", "hows", "i", "id", "ill", "im", "ive", "if", "in", "into", "is", "isnt", "it", "its", "its", "itself", "lets", "me", "more", "most", "mustnt", "my", "myself", "no", "nor", "not", "of", "off", "on", "once", "only", "or", "other", "ought", "our", "ours", "ourselves", "out", "over", "own", "same", "shant", "she", "shed", "shell", "shes", "should", "shouldnt", "so", "some", "such", "than", "that", "thats", "the", "their", "theirs", "them", "themselves", "then", "there", "theres", "these", "they", "theyd", "theyll", "theyre", "theyve", "this", "those", "through", "to", "too", "under", "until", "up", "very", "was", "wasnt", "we", "wed", "well", "were", "weve", "were", "werent", "what", "whats", "when", "whens", "where", "wheres", "which", "while", "who", "whos", "whom", "why", "whys", "with", "wont", "would", "wouldnt", "you", "youd", "youll", "youre", "youve", "your", "yours", "yourself", "yourselves"])
 
stop_words = my_stop.union(stop_words1).union(my_stop_2)
prior_truth = 0
prior_false = 0
prior_pos = 0
prior_neg = 0
stop_char = string.punctuation + '1234567890'

def readAllFile(fold):
    content_arr = []
    for fn in listdir(fold):
        #print fold + fn
        try:
            with open(fold + fn, 'r') as f:
                content_arr.append(' '.join(f.readlines()))
                f.close()
        except:
            pass
    
    return content_arr
            
def readAllFolds(fold_dir, _fold_arr=None):
    if(_fold_arr == None):
        # TODO reserved "/fold1/" from training set for dev testing
        #_fold_arr = ["/fold1/",  "/fold2/", "/fold3/", "/fold4/"] #production
        #_fold_arr = ["/fold2/", "/fold3/", "/fold4/"] ##dev testing
        _fold_arr= ['/' + f + '/' for f in listdir(fold_dir) if f[:1] != '.'] # dynamic
    # print _fold_arr 
    content_arr = []
    for fold in (fold_dir + s for s in _fold_arr):
        try:
            content_arr+=readAllFile(fold)
        except:
            pass
        
    return content_arr


def tokenize_text(content):
    # # TODO implement auto-correct using phonetics
    # # TODO handle stemming include, including
    # # TODO handle line..word -> lineword
    # Removing all punctuation and number - !"#$%&'()*+,-./:;<=>?@[\]^_`{|}~
    
    tokens = "".join([i for i in content if (i not in stop_char) ]).split()
    
    # Lower case everything
    tokens = [x.lower() for x in tokens]
    
    # Remove stop words
    tokens = [x for x in tokens if x not in stop_words]
    
    return tokens

def collectAllTokens(content_array):
    result = []
    for r in content_array:
        result += tokenize_text(r)
    return result

def log_nb(num):
    return log10(num)

def calculatePText(count_occur, token_class ,vocab):
    return log_nb( (count_occur * 1.0) / (len(token_class) + len(vocab) ) ) 


# stuff to run always here such as class/def
def main():
    # Take input dir
    baseDir = sys.argv[1]
    if baseDir[-1:] != '/' : baseDir+='/'
    
    print baseDir
    
    neg_review = readAllFolds(baseDir + NEG + FALSE)
    neg_review += readAllFolds(baseDir + NEG + TRUTH_NEG)
    
    pos_review = readAllFolds(baseDir + POS + FALSE)
    pos_review += readAllFolds(baseDir + POS + TRUTH_POS)
    
    false_review = readAllFolds(baseDir + NEG + FALSE)
    false_review += readAllFolds(baseDir + POS + FALSE)
    
    true_review = readAllFolds(baseDir + NEG + TRUTH_NEG)
    true_review += readAllFolds(baseDir + POS + TRUTH_POS)
    
    print "Done with reading all data.."
    print "Calculating priors.."
    prior_pos = log_nb( len(pos_review) / (len(pos_review) + len(neg_review) * 1.0 ) )
    prior_neg = log_nb( len(neg_review) / (len(pos_review) + len(neg_review) * 1.0 ) )
    
    prior_truth = log_nb( len(true_review) / (len(true_review) + len(false_review) * 1.0) )
    prior_false = log_nb( len(false_review) / (len(true_review) + len(false_review) * 1.0 ) )
    
    
    #list of all the tokens in each class
    true_review_token = collectAllTokens(true_review)
    false_review_token = collectAllTokens(false_review)
    pos_review_token = collectAllTokens(pos_review)
    neg_review_token = collectAllTokens(neg_review)
    
    ## Initializing counters for fast counts
    true_review_token_ctr = Counter(true_review_token)
    false_review_token_ctr = Counter(false_review_token)
    pos_review_token_ctr = Counter(pos_review_token)
    neg_review_token_ctr = Counter(neg_review_token)
    #######
    ## can optimize by using counters only and removing true_review_token etc..
    ## length can be obtained by - sum(c.itervalues())
    ########
    
    print "Done with collecting all tokens.."
    #total vocab   
    vocab = set(pos_review_token + neg_review_token)
    
#     list_s = list(vocab)
#     list_s.sort()
#     print list_s
     
    training = {}
    training[TRUE_KEY]={}
    training[FALSE_KEY]={}
    training[POS_KEY]={}
    training[NEG_KEY]={}
    
    print "Calculating P(text|x) for : {0}".format(len(vocab))
    
    for word in vocab:
        try:
            # calculating counts and adding 1 as smoothing value
            count_true = 1 + true_review_token_ctr[word]
            count_false = 1 + false_review_token_ctr[word]
            count_pos = 1 + pos_review_token_ctr[word]
            count_neg = 1 + neg_review_token_ctr[word]
            
            training[TRUE_KEY][word] = calculatePText(count_true, true_review_token, vocab) 
            training[FALSE_KEY][word] = calculatePText(count_false, false_review_token, vocab) 
            training[POS_KEY][word] = calculatePText(count_pos, pos_review_token, vocab) 
            training[NEG_KEY][word] = calculatePText(count_neg, neg_review_token, vocab)
        except:
            pass 
        
    training[TRUE_KEY][DEF_KEY] = calculatePText(1, true_review_token, vocab)
    training[FALSE_KEY][DEF_KEY] = calculatePText(1, false_review_token, vocab)
    training[POS_KEY][DEF_KEY] = calculatePText(1, pos_review_token, vocab)
    training[NEG_KEY][DEF_KEY] = calculatePText(1, neg_review_token, vocab)
        
    training[TRUE_KEY][PRIOR_KEY] = prior_truth
    training[FALSE_KEY][PRIOR_KEY] = prior_false
    training[POS_KEY][PRIOR_KEY] = prior_pos
    training[NEG_KEY][PRIOR_KEY] = prior_neg
        
    print "saving results in file"
    with open('nbmodel.txt', 'w') as f:
        f.write(str(training))
        f.close()
    
    print "done"

#Checking how many times code is executed
print __name__
if __name__ == "__main__":
   # stuff only to run when not called via 'import' here
   main() 
